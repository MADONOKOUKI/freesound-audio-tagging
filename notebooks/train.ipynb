{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "      <th>manually_verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00044347.wav</td>\n",
       "      <td>Hi-hat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001ca53d.wav</td>\n",
       "      <td>Saxophone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002d256b.wav</td>\n",
       "      <td>Trumpet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0033e230.wav</td>\n",
       "      <td>Glockenspiel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00353774.wav</td>\n",
       "      <td>Cello</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname         label  manually_verified\n",
       "0  00044347.wav        Hi-hat                  0\n",
       "1  001ca53d.wav     Saxophone                  1\n",
       "2  002d256b.wav       Trumpet                  0\n",
       "3  0033e230.wav  Glockenspiel                  1\n",
       "4  00353774.wav         Cello                  1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "      <th>manually_verified</th>\n",
       "      <th>label_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00044347.wav</td>\n",
       "      <td>Hi-hat</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001ca53d.wav</td>\n",
       "      <td>Saxophone</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002d256b.wav</td>\n",
       "      <td>Trumpet</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0033e230.wav</td>\n",
       "      <td>Glockenspiel</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00353774.wav</td>\n",
       "      <td>Cello</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname         label  manually_verified  label_idx\n",
       "0  00044347.wav        Hi-hat                  0         23\n",
       "1  001ca53d.wav     Saxophone                  1         30\n",
       "2  002d256b.wav       Trumpet                  0         38\n",
       "3  0033e230.wav  Glockenspiel                  1         19\n",
       "4  00353774.wav         Cello                  1          6"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(np.unique(train_df.label))\n",
    "train_df['label_idx'] = le.transform(train_df['label'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Acoustic_guitar', 'Applause', 'Bark', 'Bass_drum',\n",
       "       'Burping_or_eructation', 'Bus', 'Cello', 'Chime', 'Clarinet',\n",
       "       'Computer_keyboard', 'Cough', 'Cowbell', 'Double_bass',\n",
       "       'Drawer_open_or_close', 'Electric_piano', 'Fart',\n",
       "       'Finger_snapping', 'Fireworks', 'Flute', 'Glockenspiel', 'Gong',\n",
       "       'Gunshot_or_gunfire', 'Harmonica', 'Hi-hat', 'Keys_jangling',\n",
       "       'Knock', 'Laughter', 'Meow', 'Microwave_oven', 'Oboe', 'Saxophone',\n",
       "       'Scissors', 'Shatter', 'Snare_drum', 'Squeak', 'Tambourine',\n",
       "       'Tearing', 'Telephone', 'Trumpet', 'Violin_or_fiddle', 'Writing'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(le.classes_)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('labels.npy', le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load('labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00063640.wav</td>\n",
       "      <td>Laughter Hi-Hat Flute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0013a1db.wav</td>\n",
       "      <td>Laughter Hi-Hat Flute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002bb878.wav</td>\n",
       "      <td>Laughter Hi-Hat Flute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002d392d.wav</td>\n",
       "      <td>Laughter Hi-Hat Flute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00326aa9.wav</td>\n",
       "      <td>Laughter Hi-Hat Flute</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname                  label\n",
       "0  00063640.wav  Laughter Hi-Hat Flute\n",
       "1  0013a1db.wav  Laughter Hi-Hat Flute\n",
       "2  002bb878.wav  Laughter Hi-Hat Flute\n",
       "3  002d392d.wav  Laughter Hi-Hat Flute\n",
       "4  00326aa9.wav  Laughter Hi-Hat Flute"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../data/sample_submission.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(y, max_length=176400):\n",
    "    \"\"\"音声波形を固定長にそろえる\n",
    "    \n",
    "    max_lengthより長かったらランダムに切り取る\n",
    "    max_lengthより短かったらランダムにパディングする\n",
    "    \"\"\"\n",
    "    if len(y) > max_length:\n",
    "        max_offset = len(y) - max_length\n",
    "        offset = np.random.randint(max_offset)\n",
    "        y = y[offset:max_length + offset]\n",
    "    else:\n",
    "        if max_length > len(y):\n",
    "            max_offset = max_length - len(y)\n",
    "            offset = np.random.randint(max_offset)\n",
    "        else:\n",
    "            offset = 0\n",
    "        y = np.pad(y, (offset, max_length - len(y) - offset), 'constant')\n",
    "    return y\n",
    "\n",
    "\n",
    "class AudioDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, df, wav_dir, sr=None, max_length=4.0, window_size=0.02, hop_size=0.01, n_mels=64):\n",
    "        if not os.path.exists(wav_dir):\n",
    "            print('ERROR: not found %s' % wav_dir)\n",
    "            exit(1)\n",
    "        self.df = df\n",
    "        self.wav_dir = wav_dir\n",
    "        self.sr = sr\n",
    "        self.max_length = max_length     # sec\n",
    "        self.window_size = window_size   # sec\n",
    "        self.hop_size = hop_size         # sec\n",
    "        self.n_mels = n_mels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fpath = os.path.join(self.wav_dir, self.df.fname[index])\n",
    "        y, sr = librosa.load(fpath, sr=self.sr)\n",
    "        y = random_crop(y, int(self.max_length * sr))\n",
    "        \n",
    "        # feature\n",
    "        n_fft = int(self.window_size * sr)\n",
    "        hop_length = int(self.hop_size * sr)\n",
    "        mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=self.n_mels)\n",
    "        # (channel, features, frames)\n",
    "        mel = np.resize(mel, (1, mel.shape[0], mel.shape[1]))\n",
    "        tensor = torch.from_numpy(mel).float()\n",
    "\n",
    "        # label\n",
    "        label = self.df.label_idx[index]\n",
    "        \n",
    "        return tensor, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- メルスペクトログラムの標準化はどうする？\n",
    "- ファイルごとに平均0、標準偏差1でよいか？ -> GCommandsPytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9473\n",
      "torch.Size([1, 64, 401]) 23 Hi-hat\n"
     ]
    }
   ],
   "source": [
    "train_dataset = AudioDataset(train_df, '../data/audio_train')\n",
    "print(len(train_dataset))\n",
    "data, target = train_dataset[0]\n",
    "print(data.size(), target, le.classes_[target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AudioDataset(train_df, '../data/audio_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "valid_size = 0.1\n",
    "batch_size = 128\n",
    "num_workers= 0\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# 訓練データとバリデーションデータに分割\n",
    "num_train = len(train_dataset)\n",
    "indices = list(range(num_train))\n",
    "split = int(valid_size * num_train)\n",
    "np.random.shuffle(indices)\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size,\n",
    "    sampler=train_sampler,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size,\n",
    "    sampler=valid_sampler,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 7)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 64, 401])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "data, target = iter(train_loader).next()\n",
    "print(data.size())\n",
    "print(target.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet2D, self).__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 20, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(20, 20, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(25220, 1000)\n",
    "        self.fc2 = nn.Linear(1000, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.size())\n",
    "        x = self.block1(x)\n",
    "        print(x.size())\n",
    "        x = self.block2(x)\n",
    "        print(x.size())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        print(x.size())\n",
    "        x = F.relu(self.fc1(x))\n",
    "        print(x.size())\n",
    "        x = self.fc2(x)\n",
    "        print(x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 64, 401])\n",
      "torch.Size([128, 20, 30, 198])\n",
      "torch.Size([128, 20, 13, 97])\n",
      "torch.Size([128, 25220])\n",
      "torch.Size([128, 1000])\n",
      "torch.Size([128, 41])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.4669e-02,  1.0678e-02, -1.6374e-02,  ..., -1.5601e-02,\n",
       "          7.3538e-03,  2.2586e-02],\n",
       "        [ 4.0632e-02,  8.4185e-03, -3.2735e-02,  ..., -5.0126e-03,\n",
       "         -5.3709e-03,  1.9890e-02],\n",
       "        [ 3.4416e-02,  1.2960e-02, -1.8639e-02,  ..., -1.4152e-02,\n",
       "          3.2253e-03,  2.2069e-02],\n",
       "        ...,\n",
       "        [ 1.9631e-01, -1.0667e-01,  2.7603e-01,  ...,  1.1381e-01,\n",
       "         -6.7733e-01,  9.8624e-01],\n",
       "        [ 3.3981e-02,  1.1522e-02, -1.5906e-02,  ..., -1.5315e-02,\n",
       "          7.8248e-03,  2.0316e-02],\n",
       "        [ 2.2161e-01,  2.2645e-02, -2.0796e-02,  ..., -1.8583e-01,\n",
       "         -1.8259e-01,  7.2796e-02]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
